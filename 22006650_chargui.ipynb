{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "BE0VQ8_lugfh",
        "outputId": "2d0a63a2-b98b-4eb2-b9ce-1c25f51b9509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ D√âMARRAGE DU PROGRAMME...\n",
            "üì• T√©l√©chargement des donn√©es depuis les serveurs H2O.ai...\n",
            "‚úÖ Fichiers r√©cup√©r√©s avec succ√®s.\n",
            "‚öôÔ∏è Traitement des donn√©es...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 1 fields in line 42, saw 2\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2019806248.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Lecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cs-training.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cs-test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 42, saw 2\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# PROJET SCORING CR√âDIT - MODE \"AUTONOME\" (Liens H2O.ai stables)\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Biblioth√®ques Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, classification_report\n",
        "\n",
        "# Configuration visuelle\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üöÄ D√âMARRAGE DU PROGRAMME...\")\n",
        "\n",
        "# --- √âTAPE 1 : T√âL√âCHARGEMENT AUTOMATIQUE (SERVEURS STABLES) ---\n",
        "# On utilise les liens de H2O.ai qui ne changent jamais\n",
        "print(\"üì• T√©l√©chargement des donn√©es depuis les serveurs H2O.ai...\")\n",
        "\n",
        "# T√©l√©chargement Train\n",
        "if not os.path.exists('cs-training.csv'):\n",
        "    os.system('wget -q https://raw.githubusercontent.com/h2oai/h2o-2/master/smalldata/kaggle/GiveMeSomeCredit/cs-training.csv')\n",
        "\n",
        "# T√©l√©chargement Test\n",
        "if not os.path.exists('cs-test.csv'):\n",
        "    os.system('wget -q https://raw.githubusercontent.com/h2oai/h2o-2/master/smalldata/kaggle/GiveMeSomeCredit/cs-test.csv')\n",
        "\n",
        "print(\"‚úÖ Fichiers r√©cup√©r√©s avec succ√®s.\")\n",
        "\n",
        "# --- √âTAPE 2 : CHARGEMENT ET NETTOYAGE ---\n",
        "print(\"‚öôÔ∏è Traitement des donn√©es...\")\n",
        "\n",
        "# Lecture\n",
        "df_train = pd.read_csv(\"cs-training.csv\")\n",
        "df_test = pd.read_csv(\"cs-test.csv\")\n",
        "\n",
        "def clean_data(df, target_col='SeriousDlqin2yrs', is_train=True, imputer=None):\n",
        "    # Suppression colonne index (souvent nomm√©e Unnamed: 0)\n",
        "    cols_to_drop = [c for c in df.columns if 'Unnamed' in c]\n",
        "    df = df.drop(cols_to_drop, axis=1)\n",
        "\n",
        "    if is_train:\n",
        "        X = df.drop(target_col, axis=1)\n",
        "        y = df[target_col]\n",
        "        # Imputation par la m√©diane (robuste aux salaires extr√™mes)\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        X_imputed = imputer.fit_transform(X)\n",
        "    else:\n",
        "        # Pour le test, on enl√®ve la cible si elle est pr√©sente\n",
        "        if target_col in df.columns:\n",
        "            X = df.drop(target_col, axis=1)\n",
        "        else:\n",
        "            X = df\n",
        "        y = None\n",
        "        # On utilise le m√™me imputer\n",
        "        X_imputed = imputer.transform(X)\n",
        "\n",
        "    X_clean = pd.DataFrame(X_imputed, columns=X.columns)\n",
        "    return X_clean, y, imputer\n",
        "\n",
        "# Nettoyage\n",
        "X, y, imputer_model = clean_data(df_train, is_train=True)\n",
        "X_kaggle_test, _, _ = clean_data(df_test, is_train=False, imputer=imputer_model)\n",
        "\n",
        "# Split (Train / Validation Interne)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# --- √âTAPE 3 : IA (RANDOM FOREST) ---\n",
        "print(\"ü§ñ Entra√Ænement de l'IA (C'est la partie la plus longue)...\")\n",
        "# class_weight='balanced' est vital pour le cr√©dit scoring\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"‚úÖ Mod√®le entra√Æn√©.\")\n",
        "\n",
        "# --- √âTAPE 4 : VISUALISATION (Les 3 Graphes demand√©s) ---\n",
        "print(\"\\nüìä G√âN√âRATION DES GRAPHIQUES...\")\n",
        "\n",
        "# GRAPHE 1 : IMPORTANCE DES FEATURES\n",
        "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=feature_importances, y=feature_importances.index, palette=\"viridis\")\n",
        "plt.title(\"üîç GRAPHE 1 : Crit√®res d√©cisifs pour accorder un cr√©dit\", fontsize=14)\n",
        "plt.xlabel(\"Importance (%)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# GRAPHE 2 : MATRICE DE CONFUSION\n",
        "y_pred = model.predict(X_val)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "# On utilise des labels clairs pour le prof\n",
        "group_names = ['Vrais Bons Payeurs', 'Faux D√©fauts (Erreur)', 'Faux Bons Payeurs (DANGER)', 'Vrais D√©fauts']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
        "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names, group_counts)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "\n",
        "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\n",
        "plt.title('üìâ GRAPHE 2 : Matrice de Confusion (Performance R√©elle)', fontsize=16)\n",
        "plt.ylabel('R√âALIT√â', fontsize=12)\n",
        "plt.xlabel('PR√âDICTION DE L\\'IA', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# GRAPHE 3 : COURBE ROC\n",
        "y_prob = model.predict_proba(X_val)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_val, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.title('üìà GRAPHE 3 : Courbe ROC', fontsize=14)\n",
        "plt.xlabel('Taux de Faux Positifs')\n",
        "plt.ylabel('Taux de Vrais Positifs')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# --- √âTAPE 5 : FICHIER DE SOUMISSION ---\n",
        "print(\"üìù G√©n√©ration du fichier final...\")\n",
        "final_probs = model.predict_proba(X_kaggle_test)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": range(1, len(final_probs) + 1),\n",
        "    \"Probability\": final_probs\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"‚úÖ TERMIN√â ! Tout est vert.\")\n",
        "print(\"1. Les donn√©es ont √©t√© t√©l√©charg√©es automatiquement.\")\n",
        "print(\"2. Les graphes sont affich√©s ci-dessus.\")\n",
        "print(\"3. Le fichier 'submission.csv' est disponible dans le dossier √† gauche.\")\n",
        "print(\"=\"*50)"
      ]
    }
  ]
}